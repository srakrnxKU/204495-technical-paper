\documentclass{cpepaper}
\usepackage{amsmath, amssymb}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{multirow}
\usepackage{float}
\usepackage{hyperref}

\title{การจำแนกกลุ่มของสัญญาณโจมตีแบบจำลองการเรียนรู้เชิงลึก\\Clustering Analysis of Adversarial Perturbations on Deep Learning Models}
\author{\IEEEauthorblockN{ศิระกร ลำใย\IEEEauthorrefmark{1},
วัชรพัฐ เมตตานันท\IEEEauthorrefmark{2}, และ 
จิตร์ทัศน์ ฝักเจริญผล\IEEEauthorrefmark{3}}
\IEEEauthorblockA{ภาควิชาวิศวกรรมคอมพิวเตอร์ คณะวิศวกรรมศาสตร์ มหาวิทยาลัยเกษตรศาสตร์\\
Email: \IEEEauthorrefmark{1}sirakorn.l@ku.th,
\IEEEauthorrefmark{2}vacharapat@eng.src.ku.ac.th,
\IEEEauthorrefmark{3}jtf@ku.ac.th}}

\begin{document}
\maketitle
\section*{บทคัดย่อ}
บทความวิชาการนี้กล่าวถึงการฝึกสอนแบบจำลองอย่างง่ายเพื่อค้นหารูปแบบของสัญญาณรบกวนที่สามารถโจมตีชุดข้อมูลรับเข้าให้ได้ผลลัพธ์ของแบบจำลองที่ผิดเพี้ยนไปได้ โดยพิจารณาการโจมตีบนโครงข่ายประสาทเทียมแบบเชื่อมถึงกันทั่ว ซึ่งถูกฝึกสอนด้วยชุดข้อมูล MNIST ซึ่งมีชุดข้อมูลสำหรับฝึกสอนจำนวน 60,000 จุด หลังจากการฝึกสอนโครงข่ายประสาทเทียม นำข้อมูลทดสอบจำนวน 10,000 จุด มาทำการหาสัญญาณโจมตีความยาวเท่าจำนวนจุดทดสอบ และพยายามทำการเรียนรู้จัดหมวดหมู่ ผลลัพธ์ที่ได้คือคะแนนเอฟ-1 ของบางชั้นข้อมูลลดลงไปไม่มากเมื่อเทียบกับชั้นข้อมูลอื่น และผลการจัดหมวดหมู่แสดงให้เห็นถึงความสัมพันธ์บางอย่างระหว่างข้อมูลเป้าหมายตั้งต้นและคำตอบที่แบบจำลองเห็น ซึ่งอาจนำไปสู่ประเด็นใหม่ในการศึกษาการโจมตีแบบจำลองต่อไป
\vskip 12pt
\noindent คำสำคัญ: ปัญญาประดิษฐ์, จักรกลเรียนรู้, การเรียนรู้เชิงลึก, การโจมตีการเรียนรู้
\section*{Abstract}
This work present the process of training a simple deep learning model in order to find the set of perturbations that attacks the model, therefore giving out the incorrect responses. We train a fully connected deep learning model to recognise MNIST handwriting database with 60,000 training points, and find 10,000 perturbations, each to attack 10,000 testing points. The results shows a decrease in model's F-1 score after the perturbations were mixed along with the testing points. However, the performances of all classes does not equally degrade. Morover, the clustering analysis shows some intracluster relationship between the original labels of the testing points, and the labels classified by the model. This work could lightens new scopes and perspecives on the behaviour of deep learning models after attempts on adversarial attacks.
\vskip 12pt
\noindent Keywords: Artificial Intelligence, Machine Learning, Deep Learning, Adversarial Attack

\section{ความสำคัญและที่มา}
แบบจำลองจักรกลเรียนรู้ (machine learning models) นั้นถูกใช้อย่างกว้างขวางในปัจจุบัน อย่างไรก็ตามแบบจำลองใดๆ นั้นอาจมีความผิดพลาดต่อการทำการโจมตีประสงค์ร้าย (adversarial attacks) เพื่อจงใจให้ผลลัพธ์ที่แบบจำลองนั้นคาดเดามีความผิดพลาดจากผลลัพธ์ที่ควรจะเป็น \cite{45816}

ในการเรียนรู้เชิงตัวแปรเสริม (parameter-based learning) นั้น ตัวแปรเสริม (parameters) ค่าน้ำหนัก (weights) บนแบบจำลองการเรียนรู้เชิงลึก (deep learning models) เป็นตัวกำหนดความฉลาดของแบบจำลอง อาจมีตัวแปรเสริมบางชุดที่ทำให้แบบจำลองมีช่องโหว่ต่อการโจมตีประสงค์ร้าย การโจมตีนั้นอาจเกิดจากการเพิ่มสัญญาณรบกวนซึ่งผ่านการคำนวน (calculated artefacts) เข้าสู่ข้อมูลรับเข้า (inputs) ซึ่งทำให้ความผิดพลาดของแบบจำลองในการพยากรณ์คำตอบนั้นเปลี่ยนไปอย่างชัดเจน

\section{ชุดวรรณกรรมและกระบวนวิธี}

\subsection{การโจมตีการเรียนรู้ \cite{Goodfellow-et-al-2016}, \cite{kolter_madry}}

เราจะกล่าวถึงแบบจำลองที่ถูกฝึกสอนให้จัดจำแนกข้อมูลชุด $X$ และ $Y$ และพิจารณาข้อมูลรับเข้า $(x, y)$ หนึ่งจุดบนชุดทดสอบ จะนิยามข้อมูลโจมตี (adversarial) $\tilde{x}$ ว่า
\begin{equation}
    \tilde{x} = x + \eta
\end{equation}
เมื่อเรียก $\eta$ ว่าสัญญาณรบกวน (perturbations)

ข้อสังเกตที่เกิดขึ้นคือเราอาจนิยามชุดสัญญาณรบกวนดังกล่าว ว่ามีความเข้มข้น (intensity) ในระดับที่ต่ำกว่าตามนุษย์จะมองเห็น กล่าวคือเมื่อเทียบกับชุดข้อมูลรับเข้าแล้ว ช่วง (range) ของสัญญาณรบกวนนั้นน้อยกว่าช่วงของข้อมูลรับเข้าที่เป็นไปได้มาก การนิยามดังกล่าวจะใช้การนิยามเซตของสัญญาณรบกวนที่เป็นไปได้ทั้งหมด (พิจารณาว่ามีค่า $\eta$ ที่เป็นไปได้หลายค่า และแต่ละค่าโจมตีแบบจำลองได้แตกต่างกันออกไป) ว่า
\begin{equation}
    H = \{ \eta: \|\eta\|_\infty \leq \epsilon\}
    \label{perturbation-set}
\end{equation}
เมื่อนิยามให้ตัวดำเนินการนอร์มอนันต์ (infinity norm) เป็น
\begin{equation}
    \|x\|_\infty = \max_i{x_i}
\end{equation}
และค่า $\epsilon$ เป็นค่าคงที่บ่งบอกความเข้มข้นของสัญญาณมากสุดที่รับได้ โดยมากมักมีค่าน้อย

\subsection{ฟังก์ชันสูญเสีย และการฝึกสอนแบบจำลองด้วยวิธีก้าวเคลื่อนถอยหลัง}
พิจารณาการเรียนรู้แบบจำลอง $M$ จะพบว่าการหาตัวแปรเสริม (parameters) $\theta$ ที่ดีที่สุดของ $M$ นั้นทำได้ด้วยการนิยามฟังก์ชันสูญเสีย (loss function) $\ell_i $ของจุดฝึกหัด (training point) $i$ ได้ โดยให้ฟังก์ชันสูญเสียเป็นฟังก์ชันที่เปรียบเทียบเป้าหมาย (target) $y_i$ จากชุดฝึกหัด และคำตอบ $\hat{y}_i = M(x_i)$ จากชุดคุณสมบัติ (features) $x_i$ ที่ถูกป้อนเข้าแบบจำลอง

เราอาจนิยามฟังก์ชันสูญเสียอย่างง่ายได้เป็นฟังก์ชันผลของผลต่างกำลังสอง
\begin{equation}
    \ell_i = \sum_{i=1}^{M}{(\hat{y}_i - y_i)^2} = \sum_{i=1}^{M}{(M(x_i) - y_i)^2}
    \label{mse-loss}
\end{equation}
เมื่อ $M$ เป็นขนาดของเป้าหมาย (target) สังเกดว่ายิ่งค่าของ $\hat{y}_i$ และ $y_i$ ต่างกันมากเท่าใด (กล่าวคือคือยิ่งตอบผิดมากเท่าใด) ค่าดังกล่าวก็จะยิ่งเพิ่มขึ้นมากเท่านั้น อย่างไรก็ดี ในการฝึกสอนแบบจำลองการเรียนรู้เชิงการจำแนก (classification) ส่วนมาก มักใช้ฟังก์ชันสูญเสียเป็นฟังก์ชันสูญเสียแบบความวุ่นวายข้ามชั้น (cross entropy loss)
\begin{equation}
    \ell_i = -\sum_{c=1}^{M}y_{o,c}\ln(p_{o,c})
    \label{cross-entropy-loss}
\end{equation}
เมื่อ $M$ เป็นจำนวนชั้น (class) ที่เป็นไปได้ $y$ เป็นค่าฐานสองที่บ่งบอกว่าชั้นข้อมูล (class) $c$ เป็นคำตอบที่ถูกต้องสำหรับการคาดเดา (observation) $o$ และ $p$ เป็นค่าความน่าจะเป็นที่การคาดเดา $o$ ตอบว่าเป็นชั้นข้อมูล $c$

นอกจากนี้เราอาจนิยามผลรวมของฟังก์ชันสูญเสียทั่วทั้งชุดฝึกสอน
\begin{equation}
    \mathcal{L} = \sum_{i=1}^{N}{l_i}
    \label{total-loss}
\end{equation}
เป็นผลรวมของฟังก์ชันสูญเสียบนทุกจุดฝึกหัด เมื่อ $N$ เป็นขนาดของชุดฝึกหัด (training set)

อย่างไรก็ดี แม้สมการ \ref{mse-loss} และ \ref{cross-entropy-loss} จะดูเหมือนพิจารณาค่าสูญเสียที่เปลี่ยนไปเมื่อชุดของข้อมูลฝึกหัดเปลี่ยน แต่พึงระวังว่าการนิยามฟังก์ชันสูญเสียดังกล่าว มีขึ้นเพื่อทดสอบว่าค่าตัวแปรเสริม $\theta$ ใดๆ ส่งผลให้แบบจำลองให้คำตอบผิดเพี้ยนมากหรือน้อยเพียงใด สังเกตว่าการเปลี่ยนค่า $\theta$ จะส่งผลให้ค่าของ $\hat{y}$ และ $p$ ในทั้งสองสมการตามลำดับเปลี่ยนไป และทำให้ความถูกต้องของแบบจำลองเปลี่ยนไปเช่นกัน ดังนั้นเรามักเขียนฟังก์ชันสูญเสียในสมการที่ \ref{total-loss} ใหม่ให้รับค่าตัวแปรเสริม $\theta$ เข้ามาเป็น
\begin{equation}
    \mathcal{L}(\theta) = \sum_{i=1}^{N}{l_i}
    \label{total-loss-theta}
\end{equation}

การฝึกสอนแบบจำลองการเรียนรู้เชิงลึกมักใช้วิธีการเกรเดียนต์ลดหลัั่น (gradient descent) โดยพิจารณาการปรับแบบจำลองอยู่บนเกรเดียนต์ของฟังก์ชันสูญเสีย
\begin{equation}
    \theta' = \theta - l \frac{\partial}{\partial \theta}{\mathcal{L}(\theta)}
    \label{gradient-descent}
\end{equation}
เมื่อ $l$ เป็นค่าอัตราการเรียนรู้ (learning rate) โดยปกติมักมีค่าไม่มาก

หากอธิบายโดยคร่าว ขั้นตอนวิธีเกรเดียนต์ลดหลั่น พยายามหาค่าตัวแปรเสริม $\theta_{\textrm{OPT}}$ โดยการเริ่มจากการสุ่มตัวแปรเสริม $\theta$ แล้วคำนวนเกรเดียนต์ของฟังก์ชันสูญเสีย และค่อยๆ ปรับค่า $\theta$ ตามทิศตรงข้ามกับเกรเดียนต์เรื่อยๆ จนกระทั่งถึงจุดที่ฟังก์ชันสูญเสียมีค่าน้อยที่สุด

\subsection{การหาสัญญาณรบกวนด้วยวิธีการก้าวเคลื่อนถอยหลัง}

เมื่อฝึกสอนแบบจำลองการเรียนรู้เชิงลึกโดยได้ชุดตัวแปรเสริม $\theta$ สำหรับแบบจำลอง $M$ ซึ่งต่อไปนี้จะเรียกชุดแบบจำลองและตัวแปรเสริมรวมกันว่า $M_\theta$ แล้ว เมื่อให้คู่จุดข้อมูลรับเข้าและส่งออก $(x, y)$ ใดๆ เราอาจหาสัญญาณรบกวนได้ว่า
\begin{equation}
    \eta' = \eta + l \frac{\partial}{\partial \eta} \mathcal{L}\left( x \right)
    \label{adver-gradient-descent}
\end{equation}
เมื่อ $l$ เป็นค่าอัตราการเรียนรู้ (learning rate) โดยปกติมักมีค่าไม่มาก

จะสังเกตได้ว่าสมการที่ \ref{adver-gradient-descent} มีลักษณะคล้ายกับสมการที่ \ref{gradient-descent} เป็นอย่างมาก แตกต่างกันเพียงแต่เครื่องหมายบวกหรือลบ และตัวแปรเทียบสำหรับการทำอนุพันธ์หลายตัวแปร (multivariable derivation) ขอให้สังเกตว่าในขณะที่สมการ \ref{gradient-descent} พยายามหาค่า $\theta$ ที่ทำให้ฟังก์ชันสูญเสีย $\mathcal{L}$ มีค่าต่ำที่สุด สมการที่ \ref{adver-gradient-descent} กลับพยายามหาสัญญาณรบกวน $\eta$ ที่ทำให้ฟังก์ชันสูญเสีย $\mathcal{L}$ มีค่ามากที่สุด กล่าวคือตอบผิดมากที่สุด

\subsection{คำอธิบายต่อการเกิดขึ้นของสัญญาณรบกวน}

มีหลายทฤษฎีพยายามอธิบายการเกิดขึ้นของการโจมตีแบบจำลอง ซึ่งอาจยกตัวอย่างทฤษฎีและคำอธิบายได้ดังนี้

\subsubsection{การประพฤติตัวเป็นเส้นตรง}
LeCun และคณะ \cite{1412.6572} ศึกษาผลของการโจมตีที่เกิดจาก $\tilde{x}$ โดยอาจพิจารณาได้จากการคูณสมการเพื่อหาค่าส่งออกจากชุดน้ำหนัก (weights) ของชั้นแบบจำลองการเรียนรู้เชิงลึก (deep learning layers) 
\begin{equation}
    w^\top\tilde{x} = w^\top x + w^\top \eta
\end{equation}
คณะวิจัยสังเกตพฤติกรรมว่าสัญญาณรบกวน $\eta$ กระตุ้นส่วนของชุดน้ำหนักและฟังก์ชันกระตุ้น (activation function) ในแบบจำลองให้ประพฤติตัวเยี่ยงฟังก์ชันเส้นตรง (linear functions) ซึ่งการแสดงพฤติกรรมดั่งเส้นตรง (linearity) ในกรณีชายขอบ (edge case) ของข้อมูลรับเข้านั้นก่อให้เกิดความเป็นไปได้ที่แบบจำลองจะถูกโจมตี

เพื่อพิสูจน์ทฤษฎีดังกล่าว Goodfellow และคณะ พิจารณาผลความน่าจะเป็นของคำตอบที่ออกจากแบบจำลองเมื่อปรับค่า $\epsilon$ ดังแสดงในสมการที่ \ref{perturbation-set} และพบว่าความน่าจะเป็นของข้อมูลส่งออก (output) ของแต่ละชั้นข้อมูล (class) มีความสัมพันธ์เชิงเส้นตรงกับค่า $\epsilon$ ที่เพิ่มขึ้นเรื่อยๆ

\subsubsection{ทฤษฎีชุดคุณสมบัติแบบอ่อนและแบบเข้ม}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{images/strong-weak-features.pdf}
    \caption{ตัวอย่างชุดคุณสมบัติแบบอ่อน และแบบเข้มที่เป็นไปได้ จากเลข 5}
    \label{5-weak-strong}
\end{figure}

Ilyas และคณะ \cite{1905.02175} ศึกษาโครงสร้างของแบบจำลองเชิงลึก จนนำมาสู่ข้อสรุปว่า ``ช่องโหว่ในการโจมตีแบบจำลองเป็นผลโดยตรงจากความอ่อนไหวของแบบจำลองในการวางหลักการบนชุดคุณสมบัติของข้อมูล" (``Adversarial vulnerability is a direct result of our models’ sensitivity to well-generalizing features in the data")

หากกล่าวให้ละเอียด พิจารณาว่าโครงสร้างของแบบจำลองเชิงลึกสามารถเรียนรู้ชุดคุณสมบัติ (features) ของข้อมูลรับเข้าได้สองแบบ ซึ่งในงานวิจัยเรียกว่าชุดคุณสมบัติแบบอ่อน (weak features) และชุดคุณสมบัติแบบเข้ม (strong features)
\begin{itemize}
    \item ชุดคุณสมบัติแบบเข้ม คือชุดคุณสมบัติที่มนุษย์มองเห็นโดยทั่วไป กล่าวคือเป็นชุดคุณสมบัติที่มนุษย์สามารถสังเกต ทำความเข้าใจ และวางหลักการในการจำแนกได้
    \item ชุดคุณสมบัติแบบอ่อน คือชุดคุณสมบัติที่มนุษย์ไม่สามารถมองเห็น หรือมองเห็นแต่ไม่ได้หยิบมาเป็นตัวปัจจัยหลักในการตัดสินใจ และวางหลักการในการจำแนก
\end{itemize}

จะยกตัวอย่างกรณีการจำแนกเลข 5 เราอาจพิจารณาว่าเลข 5 ดังแสดงในรูปที่ \ref{5-weak-strong} ประกอบขึ้นจากขีดหนึ่งขีดแนวขวาง ขีดหนึ่งขีดแนวตั้ง และส่วนโค้งคล้ายวงกลม เป็นชุดคุุณสมบัติที่มนุษย์สังเกตและเข้าใจโดยทั่วไป รวมถึงเป็นคุณสมบัติที่มนุษย์ใช้ในการสังเกตเห็นเส้นที่เชื่อมต่อกันจนประกอบเป็นเลข 5 อย่างไรก็ตาม แบบจำลองการเรียนรู้ใดๆ อาจเห็นมุมรอยต่อระหว่างขอบ (ซึ่งอาจสังเกตได้ว่าไม่มีเลขตัวใดเลยนอกจาก 1 ถึง 9 ยกเว้น 5 ที่มีมุมและขอบดังแสดง) เป็นตัวตัดสินใจในการเรียนรู้เลข 5 อย่างไรก็ตาม พึงสังเกตว่าแบบจำลองอาจจะแม้กระทั่งเลือกสังเกตเห็นพื้นที่ว่างบริเวณที่แตกต่างกันไป และใช้พื้นที่ว่างเหล่านั้นเพื่อสร้างข้อสรุปหรือตัดสินใจว่าเลขที่มองเห็นเป็นเลขใด (ซึ่งการนำมาซึ่ง ``ข้อสรุป'' จากที่ว่างนั้น ขัดกับวิสัยปกติของมนุษย์ในการสังเกตและมองเห็นอย่างชัดเจน)

\subsection{การทดลองหาสัญญาณรบกวนบนชุดข้อมูล MNIST}

\begin{table}
    \centering
    \begin{tabular}{c|ccc|ccc}
        \hline \hline
        \multirow{2}{*}{เป้าหมาย} & \multicolumn{3}{c|}{ข้อมูลตั้งต้น} & \multicolumn{3}{c}{ข้อมูลที่ถูกโจมตี}\\
        \cline{2-7}
        & พริซิชัน & รีคอลล์ & เอฟ-1 & พริซิชัน & รีคอลล์ & เอฟ-1 \\
        \hline
        0 & 0.93 & 0.98 & 0.96 & 0.88 & 0.95 & 0.91 \\
        1 & 0.97 & 0.97 & 0.97 & 0.94 & 0.91 & 0.93 \\
        2 & 0.93 & 0.92 & 0.93 & 0.77 & 0.82 & 0.80 \\
        3 & 0.91 & 0.92 & 0.91 & 0.74 & 0.74 & 0.74 \\
        4 & 0.93 & 0.93 & 0.93 & 0.80 & 0.82 & 0.81 \\
        5 & 0.91 & 0.89 & 0.90 & 0.71 & 0.71 & 0.71 \\
        6 & 0.93 & 0.95 & 0.94 & 0.89 & 0.85 & 0.87 \\
        7 & 0.95 & 0.91 & 0.93 & 0.87 & 0.80 & 0.84 \\
        8 & 0.89 & 0.90 & 0.89 & 0.70 & 0.74 & 0.72 \\
        9 & 0.92 & 0.91 & 0.92 & 0.80 & 0.77 & 0.78\\
        \hline \hline
    \end{tabular}
    \caption{ตารางแสดงค่าพริซิชัน (precision) รีคอลล์ (recall) และคะแนน F-1 ของแบบจำลอง ก่อนและหลังการโจมตี}
    \label{model-table}
\end{table}

ในงานชิ้นนี้ ผู้เขียนทำการฝึกสอนแบบจำลองการเรียนรู้เชิงลึกแบบชั้นเชื่อมถึงกันหมด (Fully-connected Deep Learning model) บนฐานข้อมูล MNIST \cite{lecun2010mnist} ซึ่งประกอบด้วยชุดฝึกหัดจำนวน 60,000 ข้อมูล มีชุดคุณสมบัติ (features) เป็นรูปภาพลายมือเขียนตัวเลขขนาด $28 \time 28$ พิกเซลแบบขาวดำ และมีชั้นเป้าหมาย (targets) เป็นตัวเลข 1-9 ที่ปรากฎในรูป เมื่อทำการฝึกสอนแบบจำลองเป็นที่เรียบร้อย ผู้เขียนหาสัญญาณโจมตี $\eta$ จำนวน 10,000 จุด บนแต่ละจุดข้อมูลของชุดทดสอบความยาว 10,000 ข้อมูล กล่าวคือสัญญาณโจมตี $\eta_i$ โจมตีจุดทดสอบ $\left(x_i, y_i \right)$

ข้อมูลคุณสมบัติในทั้งชุดฝึกสอนและชุดทดสอบถูกปรับช่วงข้อมูล (rescale) ให้อยู่ในช่วง $\left[-1, 1\right]$ วัดผลด้วยฟังก์ชันสูญเสียแบบความซับซ้อนข้ามชั้น (cross entropy loss) ดังแสดงในสมการที่ \ref{cross-entropy-loss} ใช้อัตราการเรียนรู้ (learning rate) $l = 0.03$ และฝึกสอนเป็นจำนวน 20 รอบวนซ้ำ (epochs)

\subsection{การจำแนกกลุ่มของสัญญาณโจมตี}

พิจารณาข้อมูลฝึกหัด $(x_i, y_i)$ ซึ่งถูกสัญญาณโจมตี $\eta_i$ ทำให้แบบจำลองตอบชั้นข้อมูลของ $x_i$ ผิดเป็น $m_i$ ผู้เขียนทำการจำแนกกลุ่ม (clustering) ข้อมูลสัญญาณโจมตี $\eta$ จำนวน 10,000 ตัว โดยใช้จำนวนกลุ่ม (clusters) 10 กลุ่ม และพิจารณาว่าแต่ละกลุ่มของสัญญาณโจมตีนั้นมีเป้าหมาย $y_i$ ดั้งเดิม และคำตอบที่แบบจำลองตอบออกมาผิด $m_i$ เป็นเท่าใดบ้าง

\section{ผลลัพธ์}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{images/adversarials.pdf}
    \caption{ตัวอย่างข้อมูลที่ถูกโจมตี}
    \label{adversarials}
\end{figure}

ตัวอย่างของข้อมูลหลังถูกโจมตีด้วยสัญญาณโจมตี ดังแสดงในรูปที่ \ref{adversarials} พร้อมกับป้ายระบุว่าแบบจำลองเห็นข้อมูลที่ถูกโจมตีเป็นเลขใด

ข้อมูลแสดงอัตราพรีซิชัน (precision) รีคอลล์ (recall) และคะแนนเอฟ-1 (F-1 score) ของแบบจำลองนั้น ดังแสดงในตารางที่ \ref{model-table} โดยแยกเป็นกรณีคะแนนของชุดทดสอบก่อนการโจมตี และชุดทดสอบหลังโจมตีด้วยความเข้มสัญญาณ $\epsilon = 0.05$ (ดังแสดงในสมการที่ \ref{perturbation-set})

อาจพิจารณาได้ว่า คะแนนเอฟ-1 ของบางชั้นข้อมูล (เช่นเลข 1) ลดลงไปไม่มากเมื่อเทียบกับชั้นข้อมูลอื่น (เช่นเลข 2 และเลข 5) การพิจารณาลักษณะนี้อาจนำมาสู่สมมติฐานว่าเราไม่สามารถโจมตีเป้าหมายของแบบจำลองการเรียนรู้เชิงลึกแต่ละแบบได้ด้วยความง่ายเท่ากัน อย่างไรก็ตาม สมมติฐานดังกล่าวต้องการการทดลองอีกเป็นจำนวนมากก่อนจะสามารถสรุปได้ว่าจริงหรือไม่จริง

\section{อภิปรายผล}

\subsection{ความแม่นยำของแบบจำลองต่อสัญญาณรบกวน}

เมื่อพิจารณาคะแนนเอฟ-1 ซึ่งเป็นค่าเฉลี่ยฮาร์โมนิก (harmonic mean) ของพรีซิชัน (precision) และรีคอลล์ (recall) อาจพิจารณาได้ว่า คะแนนเอฟ-1 ของบางชั้นข้อมูล (เช่นเลข 1) ลดลงไปไม่มากเมื่อเทียบกับชั้นข้อมูลอื่น (เช่นเลข 2 และเลข 5) การพิจารณาลักษณะนี้อาจนำมาสู่สมมติฐานว่าเราไม่สามารถโจมตีเป้าหมายของแบบจำลองการเรียนรู้เชิงลึกแต่ละแบบได้ด้วยความง่ายเท่ากัน อย่างไรก็ตาม สมมติฐานดังกล่าวต้องการการทดลองอีกเป็นจำนวนมากก่อนจะสามารถสรุปได้ว่าจริงหรือไม่จริง

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{images/original-cf.pdf}
    \caption{เมทริกซ์แสดงความฉงน ระหว่างหมายเลขของกลุ่มคลัสเตอร์ และเป้าหมายตั้งต้นของข้อมูล}
    \label{original-cf}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{images/perturbs-cf.pdf}
    \caption{เมทริกซ์แสดงความฉงน ระหว่างหมายเลขของกลุ่มคลัสเตอร์ และคำตอบที่แบบจำลองเห็น}
    \label{perturbs-cf}
\end{figure}

\subsection{ความแม่นยำของแบบจำลองต่อสัญญาณรบกวน}

ภาพที่ \ref{original-cf} แสดงผลการจัดกลุ่ม (clustering) ของสัญญาณรบกวน เทียบกับเป้าหมาย (target) ตั้งต้นของข้อมูล พบว่าในคลัสเตอร์ (cluster) ที่ 1, 2, และ 4 มีสัญญาณรบกวนที่พยายามรบกวนข้อมูลเลข 2, 9, และ 1 มากเป็นพิเศษ และในคลัสเตอร์ที่ 6 มีสัญญาณรบกวนที่พยายามรบกวนข้อมูลเลข 3 และ 7 มากเป็นพิเศษ

ภาพที่ \ref{perturbs-cf} แสดงผลการจัดกลุ่ม (clustering) ของสัญญาณรบกวน เทียบกับคำตอบของเป้าหมายจากแบบจำลอง พบว่าในคลัสเตอร์ (cluster) ที่ 1, 2, และ 4 แบบจำลองมองเห็นสัญญาณรบกวนเป็นเลข 3, 6, และ 2 มากเป็นพิเศษ และในคลัสเตอร์ที่ 6 มีสัญญาณรบกวนที่พยายามรบกวนข้อมูลเลข 5 และ 8 มากเป็นพิเศษ

แม้ผู้เขียนจะยังไม่สามารถสรุปได้แน่ชัดว่าการทำการจัดหมวดหมู่ดังกล่าวแสดงถึงผลของการโจมตีอย่างไร ทว่า เป็นที่น่าสนใจว่าเราอาจสังเกตเห็นถึงความสัมพันธ์จากการจัดหมวดหมู่ เมื่อเทียบกับข้อมูลเป้าหมายตั้งต้น และคำตอบเป้าหมายของแบบจำลอง การวิเคราะห์การจัดกลุ่มในลักษณะดังกล่าว หากต่อยอดเพิ่มเติม อาจสามารถบ่งบอกถึงแนวโน้มที่แบบจำลองจะถูกโจมตีได้ (เช่น เลข 3 อาจโจมตีไปเป็นเลข 2 ได้ง่ายเป็นพิเศษ เมื่อดูจากสมาชิกของคลัสเตอร์ที่ 1)

\section{สรุป}

ผลงานชิ้นนี้มุ่งเน้นถึงการพิจารณาคะแนนการประเมินผล (evaluation) ที่ลดลงของแบบจำลองการเรียนรู้เชิงลึก (deep learning models) ที่ถูกโจมตีประสงค์ร้าย (adversarial attack) ผลการทดลองชี้ให้เห็นว่าอัตราการลดลงของแต่ละเป้าหมาย (target) ไม่เท่ากัน ซึ่งอาจศึกษาเพิ่มเติมได้ว่าเป้าหมายแต่ละเป้าหมายถูกโจมตีได้ด้วยระดับความยากง่ายต่างกัน นอกจากนี้ การวิเคราะห์กลุ่ม (clustering) ยังแสดงให้เห็นถึงแนวโน้มที่กลุ่มของสัญญาณรบกวนจะมีความสัมพันธ์กันในลักษณะที่อาจนำไปสู่การศึกษาเพิ่มเติมได้ว่าชุดของข้อมูลที่มีเป้าหมาย (target) เหมือนกัน จะถูกโจมตีและทำให้แบบจำลองเห็นเป็นเป้าหมายกลุ่มเดียวกัน

\renewcommand{\refname}{เอกสารอ้างอิง}
\bibliography{references/references} 
\bibliographystyle{ieeetr}
\end{document}