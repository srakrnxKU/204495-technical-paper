\documentclass{cpepaper}
\usepackage{ragged2e}
\usepackage{amsmath, amssymb}

\title{การจำแนกกลุ่มของสัญญาณโจมตีแบบจำลองการเรียนรู้เชิงลึก}
\entitle{Clustering Analysis of Deep Learning Adversarial Perturbations}
\author{ศิระกร ลำใย}

\begin{document}
\maketitle
\begin{multicols*}{2}
    \justify
\section*{บทคัดย่อ}
บทความวิชาการนี้กล่าวถึงการฝึกสอนแบบจำลองอย่างง่ายเพื่อค้นหารูปแบบของสัญญาณรบกวนที่สามารถโจมตีชุดข้อมูลรับเข้าให้ได้ผลลัพธ์ของแบบจำลองที่ผิดเพี้ยนไปได้ โดยพิจารณาการโจมตีบนโครงข่ายประสาทเทียมแบบเชื่อมถึงกันทั่ว และโครงข่ายประสาทเทียมแบบสังวัฒนาการ โครงข่ายประสาทเทียมทั้งสองแบบถูกฝึกสอนด้วยชุดข้อมูล MNIST ซึ่งมีชุดข้อมูลสำหรับฝึกสอนจำนวน 60,000 จุด หลังจากการฝึกสอนโครงข่ายประสาทเทียม นำข้อมูลทดสอบจำนวน 10,000 จุด มาทำการหาสัญญาณโจมตีความยาวเท่าจำนวนจุดทดสอบ และพยายามทำการเรียนรู้จัดหมวดหมู่ ผลลัพธ์ที่ได้คือ\dots
\vskip 12pt
\noindent คำสำคัญ: ปัญญาประดิษฐ์, จักรกลเรียนรู้, การเรียนรู้เชิงลึก, การโจมตีการเรียนรู้
\section*{Abstract}
blablabla
\vskip 12pt
\noindent Keywords: Artificial Intelligence, Machine Learning, Deep Learning, Adversarial Attack

\section{ความสำคัญและที่มา}
แบบจำลองจักรกลเรียนรู้ (machine learning models) นั้นถูกใช้อย่างกว้างขวางในปัจจุบัน อย่างไรก็ตามแบบจำลองใดๆ นั้นอาจมีความผิดพลาดต่อการทำการโจมตีประสงค์ร้าย (adversarial attacks) เพื่อจงใจให้ผลลัพธ์ที่แบบจำลองนั้นคาดเดามีความผิดพลาดจากผลลัพธ์ที่ควรจะเป็น

ในการเรียนรู้เชิงตัวแปรเสริม (parameter-based learning) นั้น ตัวแปรเสริม (parameters) ค่าน้ำหนัก (weights) บนแบบจำลองการเรียนรู้เชิงลึก (deep learning models) เป็นตัวกำหนดความฉลาดของแบบจำลอง อาจมีตัวแปรเสริมบางชุดที่ทำให้แบบจำลองมีช่องโหว่ต่อการโจมตีประสงค์ร้าย การโจมตีนั้นอาจเกิดจากการเพิ่มสัญญาณรบกวนซึ่งผ่านการคำนวน (calculated artefacts) เข้าสู่ข้อมูลรับเข้า (inputs) ซึ่งทำให้ความผิดพลาดของแบบจำลองในการพยากรณ์คำตอบนั้นเปลี่ยนไปอย่างชัดเจน

\section{ชุดวรรณกรรมและกระบวนวิธี}

\subsection{การโจมตีการเรียนรู้}

เราจะกล่าวถึงแบบจำลองที่ถูกฝึกสอนให้จัดจำแนกข้อมูลชุด $X$ และ $Y$ และพิจารณาข้อมูลรับเข้า $(x, y)$ หนึ่งจุดบนชุดทดสอบ จะนิยามข้อมูลโจมตี (adversarial) $\tilde{x}$ ว่า
\begin{equation}
    \tilde{x} = x + \eta
\end{equation}
เมื่อเรียก $\eta$ ว่าสัญญาณรบกวน (perturbations)

ข้อสังเกตที่เกิดขึ้นคือเราอาจะนิยามชุดสัญญาณรบกวนดังกล่าว ว่ามีความเข้มข้น (intensity) ในระดับที่ต่ำกว่าตามนุษย์จะมองเห็น กล่าวคือเมื่อเทียบกับชุดข้อมูลรับเข้าแล้ว ช่วง (range) ของสัญญาณรบกวนนั้นน้อยกว่าช่วงของข้อมูลรับเข้าที่เป็นไปได้มาก การนิยามดังกล่าวจะใช้การนิยามเซตของสัญญาณรบกวนที่เป็นไปได้ทั้งหมด (พิจารณาว่ามีค่า $\eta$ ที่เป็นไปได้หลายค่า และแต่ละค่าโจมตีแบบจำลองได้แตกต่างกันออกไป) ว่า
\begin{equation}
    H = \{ \eta: \|\eta\|_\infty \leq \epsilon\}
\end{equation}
เมื่อนิยามให้ตัวดำเนินการนอร์มอนันต์ (infinity norm) เป็น
\begin{equation}
    \|x\|_\infty = \max_i{x_i}
\end{equation}

\subsection{การหาสัญญาณรบกวนด้วยวิธีการก้าวเคลื่อนถอยหลัง}

พิจารณาการเรียนรู้แบบจำลอง $M$ จะพบว่าการหาตัวแปรเสริม (parameters) $\theta$ ที่ดีที่สุดของ $M$ นั้นทำได้ด้วยการนิยามฟังก์ชันสูญเสีย (loss function) $\ell_i $ของจุดฝึกหัด (training point) $i$ ได้ โดยให้ฟังก์ชันสูญเสียเป็นฟังก์ชันที่เปรียบเทียบเป้าหมาย (target) $y_i$ จากชุดฝึกหัด และคำตอบ $\hat{y}_i = M(x_i)$ จากชุดคุณสมบัติ (features) $x_i$ ที่ถูกป้อนเข้าแบบจำลอง

เราอาจนิยามฟังก์ชันสูญเสียอย่างง่ายได้เป็นฟังก์ชันผลของผลต่างกำลังสอง
\begin{equation}
    \ell_i = \sum_{i=1}^{M}{(\hat{y}_i - y_i)^2} = \sum_{i=1}^{M}{(M(x_i) - y_i)^2}
\end{equation}
เมื่อ $M$ เป็นขนาดของเป้าหมาย (target) สังเกดว่ายิ่งค่าของ $\hat{y}_i$ และ $y_i$ ต่างกันมากเท่าใด (มองอีกมุมหนึ่ง คือยิ่งตอบผิดมากเท่าใด) ค่าดังกล่าวก็จะยิ่งเพิ่มขึ้นมากเท่านั้น

นอกจากนี้เราอาจนิยามผลรวมของฟังก์ชันสูญเสียทั่วทั้งชุดฝึกสอน
\begin{equation}
    \mathcal{L} = \sum_{i=1}^{N}{l_i}
\end{equation}
ซึ่งเป็นผลรวมของฟังก์ชันสูญเสียบนทุกจุดฝึกหัด เมื่อ $N$ เป็นขนาดของชุดฝึกหัด (training set)

\subsection{คำอธิบายต่อการเกิดขึ้นของสัญญาณรบกวน}

มีหลายทฤษฎีพยายามอธิบายการเกิดขึ้นของการโจมตีแบบจำลอง ซึ่งอาจยกตัวอย่างทฤษฎีและคำอธิบายได้ดังนี้
\subsubsection{การประพฤติตัวเป็นเส้นตรง}
Goodfellow และคณะ พิจารณาลของการโจมตีที่เกิดจาก $\tilde{x}$ อาจพิจารณาได้จากการคูณสมการเพื่อหาค่าส่งออกจากชุดน้ำหนัก (weights) ของชั้นแบบจำลองการเรียนรู้เชิงลึก (deep learning layers) 
\begin{equation}
    w^\top\tilde{x} = w^\top x + w^\top \eta
\end{equation}
คณะวิจัยสังเกตพฤติกรรมว่าสัญญาณรบกวน $\eta$ กระตุ้นส่วนของชุดน้ำหนักและฟังก์ชันกระตุ้น (activation function) ในแบบจำลองให้ประพฤติตัวเยี่ยงฟังก์ชันเส้นตรง (linear functions) ซึ่งการประพฤติตัวเป็นฟังก์ชันเส้นตรงในกรณีชายขอบ (edge case) ของข้อมูลรับเข้านั้นก่อให้เกิดความเป็นไปได้ที่แบบจำลองจะถูกโจมตี

\subsection{การทดลองหาสัญญาณรบกวนบนชุดข้อมูล MNIST}

\subsection{การจำแนกกลุ่มของสัญญาณรบกวน}

\section{ผลลัพธ์}

\section{อภิปรายผล}

\section{สรุป}

\end{multicols*}
\end{document}